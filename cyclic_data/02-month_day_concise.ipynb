{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf15564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cb03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DARK_READER = True\n",
    "if DARK_READER:\n",
    "    plt.rcParams.update({\n",
    "        \"lines.color\": \"white\",\n",
    "        \"patch.edgecolor\": \"white\",\n",
    "        \"text.color\": \"black\",\n",
    "        \"axes.facecolor\": \"black\",\n",
    "        \"axes.edgecolor\": \"lightgray\",\n",
    "        \"axes.labelcolor\": \"white\",\n",
    "        \"xtick.color\": \"white\",\n",
    "        \"ytick.color\": \"white\",\n",
    "        \"grid.color\": \"lightgray\",\n",
    "        \"figure.facecolor\": \"black\",\n",
    "        \"figure.edgecolor\": \"black\",\n",
    "        \"savefig.facecolor\": \"black\",\n",
    "        \"savefig.edgecolor\": \"black\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceae51e",
   "metadata": {},
   "source": [
    "# Season Dataset (Version 2)\n",
    "In this version, we will have the `month` feature like in version 1. In addition to that, we have added a new `day` feature.\n",
    "It is still a model for the seasons in Northern semisphere, and\n",
    "we set the following rule:\n",
    "\n",
    "- Spring: 1st March to end May (inclusive)\n",
    "- Summer: 1st June to end August\n",
    "- Autumn: 1st September to end November\n",
    "- Winter: 1st December to end February"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816caf9",
   "metadata": {},
   "source": [
    "Let's make a list named `L_month_day` as follows:\n",
    "\n",
    "```python\n",
    "print(L_month_day)\n",
    "\n",
    "[[1,1],\n",
    " [1,2],\n",
    " ...,\n",
    " [1,31],\n",
    " [2,1],\n",
    " ...,\n",
    " [2,28],\n",
    " ...,\n",
    " [12,31],\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11828e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01444950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 1,  4],\n",
       "       [ 1,  5],\n",
       "       [ 1,  6],\n",
       "       [ 1,  7],\n",
       "       [ 1,  8],\n",
       "       [ 1,  9],\n",
       "       [ 1, 10],\n",
       "       [ 1, 11],\n",
       "       [ 1, 12],\n",
       "       [ 1, 13],\n",
       "       [ 1, 14],\n",
       "       [ 1, 15],\n",
       "       [ 1, 16],\n",
       "       [ 1, 17],\n",
       "       [ 1, 18],\n",
       "       [ 1, 19],\n",
       "       [ 1, 20],\n",
       "       [ 1, 21],\n",
       "       [ 1, 22],\n",
       "       [ 1, 23],\n",
       "       [ 1, 24],\n",
       "       [ 1, 25],\n",
       "       [ 1, 26],\n",
       "       [ 1, 27],\n",
       "       [ 1, 28],\n",
       "       [ 1, 29],\n",
       "       [ 1, 30],\n",
       "       [ 1, 31],\n",
       "       [ 2,  1],\n",
       "       [ 2,  2],\n",
       "       [ 2,  3],\n",
       "       [ 2,  4],\n",
       "       [ 2,  5],\n",
       "       [ 2,  6],\n",
       "       [ 2,  7],\n",
       "       [ 2,  8],\n",
       "       [ 2,  9],\n",
       "       [ 2, 10],\n",
       "       [ 2, 11],\n",
       "       [ 2, 12],\n",
       "       [ 2, 13],\n",
       "       [ 2, 14],\n",
       "       [ 2, 15],\n",
       "       [ 2, 16],\n",
       "       [ 2, 17],\n",
       "       [ 2, 18],\n",
       "       [ 2, 19],\n",
       "       [ 2, 20],\n",
       "       [ 2, 21],\n",
       "       [ 2, 22],\n",
       "       [ 2, 23],\n",
       "       [ 2, 24],\n",
       "       [ 2, 25],\n",
       "       [ 2, 26],\n",
       "       [ 2, 27],\n",
       "       [ 2, 28],\n",
       "       [ 3,  1],\n",
       "       [ 3,  2],\n",
       "       [ 3,  3],\n",
       "       [ 3,  4],\n",
       "       [ 3,  5],\n",
       "       [ 3,  6],\n",
       "       [ 3,  7],\n",
       "       [ 3,  8],\n",
       "       [ 3,  9],\n",
       "       [ 3, 10],\n",
       "       [ 3, 11],\n",
       "       [ 3, 12],\n",
       "       [ 3, 13],\n",
       "       [ 3, 14],\n",
       "       [ 3, 15],\n",
       "       [ 3, 16],\n",
       "       [ 3, 17],\n",
       "       [ 3, 18],\n",
       "       [ 3, 19],\n",
       "       [ 3, 20],\n",
       "       [ 3, 21],\n",
       "       [ 3, 22],\n",
       "       [ 3, 23],\n",
       "       [ 3, 24],\n",
       "       [ 3, 25],\n",
       "       [ 3, 26],\n",
       "       [ 3, 27],\n",
       "       [ 3, 28],\n",
       "       [ 3, 29],\n",
       "       [ 3, 30],\n",
       "       [ 3, 31],\n",
       "       [ 4,  1],\n",
       "       [ 4,  2],\n",
       "       [ 4,  3],\n",
       "       [ 4,  4],\n",
       "       [ 4,  5],\n",
       "       [ 4,  6],\n",
       "       [ 4,  7],\n",
       "       [ 4,  8],\n",
       "       [ 4,  9],\n",
       "       [ 4, 10],\n",
       "       [ 4, 11],\n",
       "       [ 4, 12],\n",
       "       [ 4, 13],\n",
       "       [ 4, 14],\n",
       "       [ 4, 15],\n",
       "       [ 4, 16],\n",
       "       [ 4, 17],\n",
       "       [ 4, 18],\n",
       "       [ 4, 19],\n",
       "       [ 4, 20],\n",
       "       [ 4, 21],\n",
       "       [ 4, 22],\n",
       "       [ 4, 23],\n",
       "       [ 4, 24],\n",
       "       [ 4, 25],\n",
       "       [ 4, 26],\n",
       "       [ 4, 27],\n",
       "       [ 4, 28],\n",
       "       [ 4, 29],\n",
       "       [ 4, 30],\n",
       "       [ 5,  1],\n",
       "       [ 5,  2],\n",
       "       [ 5,  3],\n",
       "       [ 5,  4],\n",
       "       [ 5,  5],\n",
       "       [ 5,  6],\n",
       "       [ 5,  7],\n",
       "       [ 5,  8],\n",
       "       [ 5,  9],\n",
       "       [ 5, 10],\n",
       "       [ 5, 11],\n",
       "       [ 5, 12],\n",
       "       [ 5, 13],\n",
       "       [ 5, 14],\n",
       "       [ 5, 15],\n",
       "       [ 5, 16],\n",
       "       [ 5, 17],\n",
       "       [ 5, 18],\n",
       "       [ 5, 19],\n",
       "       [ 5, 20],\n",
       "       [ 5, 21],\n",
       "       [ 5, 22],\n",
       "       [ 5, 23],\n",
       "       [ 5, 24],\n",
       "       [ 5, 25],\n",
       "       [ 5, 26],\n",
       "       [ 5, 27],\n",
       "       [ 5, 28],\n",
       "       [ 5, 29],\n",
       "       [ 5, 30],\n",
       "       [ 5, 31],\n",
       "       [ 6,  1],\n",
       "       [ 6,  2],\n",
       "       [ 6,  3],\n",
       "       [ 6,  4],\n",
       "       [ 6,  5],\n",
       "       [ 6,  6],\n",
       "       [ 6,  7],\n",
       "       [ 6,  8],\n",
       "       [ 6,  9],\n",
       "       [ 6, 10],\n",
       "       [ 6, 11],\n",
       "       [ 6, 12],\n",
       "       [ 6, 13],\n",
       "       [ 6, 14],\n",
       "       [ 6, 15],\n",
       "       [ 6, 16],\n",
       "       [ 6, 17],\n",
       "       [ 6, 18],\n",
       "       [ 6, 19],\n",
       "       [ 6, 20],\n",
       "       [ 6, 21],\n",
       "       [ 6, 22],\n",
       "       [ 6, 23],\n",
       "       [ 6, 24],\n",
       "       [ 6, 25],\n",
       "       [ 6, 26],\n",
       "       [ 6, 27],\n",
       "       [ 6, 28],\n",
       "       [ 6, 29],\n",
       "       [ 6, 30],\n",
       "       [ 7,  1],\n",
       "       [ 7,  2],\n",
       "       [ 7,  3],\n",
       "       [ 7,  4],\n",
       "       [ 7,  5],\n",
       "       [ 7,  6],\n",
       "       [ 7,  7],\n",
       "       [ 7,  8],\n",
       "       [ 7,  9],\n",
       "       [ 7, 10],\n",
       "       [ 7, 11],\n",
       "       [ 7, 12],\n",
       "       [ 7, 13],\n",
       "       [ 7, 14],\n",
       "       [ 7, 15],\n",
       "       [ 7, 16],\n",
       "       [ 7, 17],\n",
       "       [ 7, 18],\n",
       "       [ 7, 19],\n",
       "       [ 7, 20],\n",
       "       [ 7, 21],\n",
       "       [ 7, 22],\n",
       "       [ 7, 23],\n",
       "       [ 7, 24],\n",
       "       [ 7, 25],\n",
       "       [ 7, 26],\n",
       "       [ 7, 27],\n",
       "       [ 7, 28],\n",
       "       [ 7, 29],\n",
       "       [ 7, 30],\n",
       "       [ 7, 31],\n",
       "       [ 8,  1],\n",
       "       [ 8,  2],\n",
       "       [ 8,  3],\n",
       "       [ 8,  4],\n",
       "       [ 8,  5],\n",
       "       [ 8,  6],\n",
       "       [ 8,  7],\n",
       "       [ 8,  8],\n",
       "       [ 8,  9],\n",
       "       [ 8, 10],\n",
       "       [ 8, 11],\n",
       "       [ 8, 12],\n",
       "       [ 8, 13],\n",
       "       [ 8, 14],\n",
       "       [ 8, 15],\n",
       "       [ 8, 16],\n",
       "       [ 8, 17],\n",
       "       [ 8, 18],\n",
       "       [ 8, 19],\n",
       "       [ 8, 20],\n",
       "       [ 8, 21],\n",
       "       [ 8, 22],\n",
       "       [ 8, 23],\n",
       "       [ 8, 24],\n",
       "       [ 8, 25],\n",
       "       [ 8, 26],\n",
       "       [ 8, 27],\n",
       "       [ 8, 28],\n",
       "       [ 8, 29],\n",
       "       [ 8, 30],\n",
       "       [ 8, 31],\n",
       "       [ 9,  1],\n",
       "       [ 9,  2],\n",
       "       [ 9,  3],\n",
       "       [ 9,  4],\n",
       "       [ 9,  5],\n",
       "       [ 9,  6],\n",
       "       [ 9,  7],\n",
       "       [ 9,  8],\n",
       "       [ 9,  9],\n",
       "       [ 9, 10],\n",
       "       [ 9, 11],\n",
       "       [ 9, 12],\n",
       "       [ 9, 13],\n",
       "       [ 9, 14],\n",
       "       [ 9, 15],\n",
       "       [ 9, 16],\n",
       "       [ 9, 17],\n",
       "       [ 9, 18],\n",
       "       [ 9, 19],\n",
       "       [ 9, 20],\n",
       "       [ 9, 21],\n",
       "       [ 9, 22],\n",
       "       [ 9, 23],\n",
       "       [ 9, 24],\n",
       "       [ 9, 25],\n",
       "       [ 9, 26],\n",
       "       [ 9, 27],\n",
       "       [ 9, 28],\n",
       "       [ 9, 29],\n",
       "       [ 9, 30],\n",
       "       [10,  1],\n",
       "       [10,  2],\n",
       "       [10,  3],\n",
       "       [10,  4],\n",
       "       [10,  5],\n",
       "       [10,  6],\n",
       "       [10,  7],\n",
       "       [10,  8],\n",
       "       [10,  9],\n",
       "       [10, 10],\n",
       "       [10, 11],\n",
       "       [10, 12],\n",
       "       [10, 13],\n",
       "       [10, 14],\n",
       "       [10, 15],\n",
       "       [10, 16],\n",
       "       [10, 17],\n",
       "       [10, 18],\n",
       "       [10, 19],\n",
       "       [10, 20],\n",
       "       [10, 21],\n",
       "       [10, 22],\n",
       "       [10, 23],\n",
       "       [10, 24],\n",
       "       [10, 25],\n",
       "       [10, 26],\n",
       "       [10, 27],\n",
       "       [10, 28],\n",
       "       [10, 29],\n",
       "       [10, 30],\n",
       "       [10, 31],\n",
       "       [11,  1],\n",
       "       [11,  2],\n",
       "       [11,  3],\n",
       "       [11,  4],\n",
       "       [11,  5],\n",
       "       [11,  6],\n",
       "       [11,  7],\n",
       "       [11,  8],\n",
       "       [11,  9],\n",
       "       [11, 10],\n",
       "       [11, 11],\n",
       "       [11, 12],\n",
       "       [11, 13],\n",
       "       [11, 14],\n",
       "       [11, 15],\n",
       "       [11, 16],\n",
       "       [11, 17],\n",
       "       [11, 18],\n",
       "       [11, 19],\n",
       "       [11, 20],\n",
       "       [11, 21],\n",
       "       [11, 22],\n",
       "       [11, 23],\n",
       "       [11, 24],\n",
       "       [11, 25],\n",
       "       [11, 26],\n",
       "       [11, 27],\n",
       "       [11, 28],\n",
       "       [11, 29],\n",
       "       [11, 30],\n",
       "       [12,  1],\n",
       "       [12,  2],\n",
       "       [12,  3],\n",
       "       [12,  4],\n",
       "       [12,  5],\n",
       "       [12,  6],\n",
       "       [12,  7],\n",
       "       [12,  8],\n",
       "       [12,  9],\n",
       "       [12, 10],\n",
       "       [12, 11],\n",
       "       [12, 12],\n",
       "       [12, 13],\n",
       "       [12, 14],\n",
       "       [12, 15],\n",
       "       [12, 16],\n",
       "       [12, 17],\n",
       "       [12, 18],\n",
       "       [12, 19],\n",
       "       [12, 20],\n",
       "       [12, 21],\n",
       "       [12, 22],\n",
       "       [12, 23],\n",
       "       [12, 24],\n",
       "       [12, 25],\n",
       "       [12, 26],\n",
       "       [12, 27],\n",
       "       [12, 28],\n",
       "       [12, 29],\n",
       "       [12, 30],\n",
       "       [12, 31]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(L_month_day)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02ad415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rule1 = []\n",
    "for month, _ in L_month_day:\n",
    "    if MAR <= month <= MAY:\n",
    "        y_rule1.append(SPRING)\n",
    "    elif JUN <= month <= AUG:\n",
    "        y_rule1.append(SUMMER)\n",
    "    elif SEP <= month <= NOV:\n",
    "        y_rule1.append(AUTUMN)\n",
    "    else:\n",
    "        y_rule1.append(WINTER)\n",
    "y_rule1[0:-1:31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535c16f",
   "metadata": {},
   "source": [
    "## How to Split Train/Test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89174e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1237e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rule1 = np.array(y_rule1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cb2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=SEED)\n",
    "# stratified shuffling based on `month`\n",
    "for train_indices, test_indices in split.split(X, X[:, 0]):\n",
    "    pass\n",
    "X_train_raw = X[train_indices, :]\n",
    "X_test_raw = X[test_indices, :]\n",
    "y_rule1_train = y_rule1[train_indices]\n",
    "y_rule1_test = y_rule1[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed566b",
   "metadata": {},
   "source": [
    "## First Dataset, First Model\n",
    "Just take `X_train_raw` and `X_test_raw` to train a few ML models and see what that gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19b73eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(multi_class=\"ovr\")\n",
    "softmax_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "#svm_clf = SVC(probability=True)\n",
    "svm_clf = SVC()\n",
    "#rnd_clf = RandomForestClassifier()\n",
    "T_classifiers = (log_clf, softmax_clf, tree_clf, svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c76c02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SoftmaxRegression)\n",
      "acc = 0.67, precision = 0.57, recall = 0.67\n",
      "\n",
      "(SoftmaxRegression)\n",
      "acc = 0.64, precision = 0.57, recall = 0.64\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 1.00, precision = 1.00, recall = 1.00\n",
      "\n",
      "(SVC)\n",
      "acc = 0.82, precision = 0.87, recall = 0.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_raw, y_rule1_train)\n",
    "    y_pred = clf.predict(X_test_raw)\n",
    "    \n",
    "    acc = accuracy_score(y_rule1_test, y_pred)\n",
    "\n",
    "    ## ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
    "    #precision = precision_score(y_rule1_test, y_pred)\n",
    "    ## TypeError: unsupported format string passed to numpy.ndarray.__format__\n",
    "    #precision = precision_score(y_rule1_test, y_pred, average=None)\n",
    "    precision = precision_score(y_rule1_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    #recall = recall_score(y_rule1_test, y_pred)\n",
    "    #recall = recall_score(y_rule1_test, y_pred, average=None)\n",
    "    recall = recall_score(y_rule1_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.2f}, precision = {precision:.2f}, recall = {recall:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ece67b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SoftmaxRegression)\n",
      "acc = 0.65, precision = 0.65, recall = 0.65\n",
      "\n",
      "(SoftmaxRegression)\n",
      "acc = 0.64, precision = 0.64, recall = 0.64\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 1.00, precision = 1.00, recall = 1.00\n",
      "\n",
      "(SVC)\n",
      "acc = 0.88, precision = 0.88, recall = 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What about performance on the training data?\n",
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_raw, y_rule1_train)\n",
    "    y_pred = clf.predict(X_train_raw)\n",
    "    acc = accuracy_score(y_rule1_train, y_pred)\n",
    "    precision = precision_score(y_rule1_train, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule1_train, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.2f}, precision = {precision:.2f}, recall = {recall:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16ecc5",
   "metadata": {},
   "source": [
    "We see that\n",
    "\n",
    "- Random forest performances perfectly. So does decision tree.\n",
    "\n",
    "Maybe the task is too simple. Even without taking the cyclic nature into consideration, some of the classifiers\n",
    "can already reach near perfect performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f612f9",
   "metadata": {},
   "source": [
    "# Season Dataset (Version 3)\n",
    "In this version, we will have exactly the same features like in version 2.<br>\n",
    "Only that we set a diff rule to increase the difficulty:\n",
    "\n",
    "- Spring: 15th March to 14th June (inclusive)\n",
    "- Summer: 15th June to 14th September\n",
    "- Autumn: 15th September to 14th December\n",
    "- Winter: 15th December to 14th March\n",
    "\n",
    "**N.B.** Note that we just need to create a new label, `y_rule2`. No need to modify `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38fd8040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 0, 0, 0, 1, 1, 1, 2, 2, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rule2 = []\n",
    "start = 15\n",
    "end = 14\n",
    "for month_day in L_month_day:\n",
    "    if [MAR,start] <= month_day <= [JUN,end]:\n",
    "        y_rule2.append(SPRING)\n",
    "    elif [JUN,start] <= month_day <= [SEP,end]:\n",
    "        y_rule2.append(SUMMER)\n",
    "    elif [SEP,start] <= month_day <= [DEC,end]:\n",
    "        y_rule2.append(AUTUMN)\n",
    "    else:\n",
    "        y_rule2.append(WINTER)\n",
    "\n",
    "y_rule2[0:-1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24205e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rule2 = np.array(y_rule2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e9ec218",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rule2_train = y_rule2[train_indices]\n",
    "y_rule2_test = y_rule2[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1259deeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.7123, precision = 0.7123, recall = 0.7123\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n",
      "(SVC)\n",
      "acc = 0.8630, precision = 0.8630, recall = 0.8630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_raw, y_rule2_train)\n",
    "    y_pred = clf.predict(X_test_raw)\n",
    "    acc = accuracy_score(y_rule2_test, y_pred)\n",
    "    precision = precision_score(y_rule2_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_test, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b7a57",
   "metadata": {},
   "source": [
    "In this case, our <s>random forest</s> and decision tree classifies are no longer perfect (even though still perform with high accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168b3519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.7432, precision = 0.7432, recall = 0.7432\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n",
      "(SVC)\n",
      "acc = 0.9075, precision = 0.9075, recall = 0.9075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On training set\n",
    "for clf in T_classifiers:\n",
    "    y_pred = clf.predict(X_train_raw)\n",
    "    acc = accuracy_score(y_rule2_train, y_pred)\n",
    "    precision = precision_score(y_rule2_train, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_train, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f607e",
   "metadata": {},
   "source": [
    "Let's see whether incorporating the cyclic nature improves the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c3bbc",
   "metadata": {},
   "source": [
    "## Cyclic Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0234ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01bf2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cyclic = np.c_[\n",
    "    cyclicize_series(X[:, 0], max_=12, min_=0),\n",
    "    cyclicize_series(X[:, 1], max_=31, min_=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6924fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cyclic = X_cyclic[train_indices]\n",
    "X_test_cyclic = X_cyclic[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "538b9904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.7945, precision = 0.7945, recall = 0.7945\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n",
      "(SVC)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On test set (rule2)\n",
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_cyclic, y_rule2_train)\n",
    "    y_pred = clf.predict(X_test_cyclic)\n",
    "    acc = accuracy_score(y_rule2_test, y_pred)\n",
    "    precision = precision_score(y_rule2_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_test, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ab1e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.8219, precision = 0.8219, recall = 0.8219\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n",
      "(SVC)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On training set (rule2)\n",
    "for clf in T_classifiers:\n",
    "    y_pred = clf.predict(X_train_cyclic)\n",
    "    acc = accuracy_score(y_rule2_train, y_pred)\n",
    "    precision = precision_score(y_rule2_train, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_train, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f192be87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n",
      "(SVC)\n",
      "acc = 1.0000, precision = 1.0000, recall = 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On test set (rule1)\n",
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_cyclic, y_rule1_train)\n",
    "    y_pred = clf.predict(X_test_cyclic)\n",
    "    acc = accuracy_score(y_rule1_test, y_pred)\n",
    "    precision = precision_score(y_rule1_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule1_test, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20340e",
   "metadata": {},
   "source": [
    "## Putting Together for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eff76874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.7123, precision = 0.7123, recall = 0.7123\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n",
      "(SVC)\n",
      "acc = 0.8630, precision = 0.8630, recall = 0.8630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rule 2, non-cyclic\n",
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_raw, y_rule2_train)\n",
    "    y_pred = clf.predict(X_test_raw)\n",
    "    acc = accuracy_score(y_rule2_test, y_pred)\n",
    "    precision = precision_score(y_rule2_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_test, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dd431e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression)\n",
      "acc = 0.7945, precision = 0.7945, recall = 0.7945\n",
      "\n",
      "(DecisionTreeClassifier)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n",
      "(SVC)\n",
      "acc = 0.9726, precision = 0.9726, recall = 0.9726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rule 2, cyclic\n",
    "for clf in T_classifiers:\n",
    "    clf.fit(X_train_cyclic, y_rule2_train)\n",
    "    y_pred = clf.predict(X_test_cyclic)\n",
    "    acc = accuracy_score(y_rule2_test, y_pred)\n",
    "    precision = precision_score(y_rule2_test, y_pred, average=\"micro\")\n",
    "    recall = recall_score(y_rule2_test, y_pred, average=\"micro\")    \n",
    "    print(f\"({clf.__class__.__name__})\\nacc = {acc:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4651f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cde07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
