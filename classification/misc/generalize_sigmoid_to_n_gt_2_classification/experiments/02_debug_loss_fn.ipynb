{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Iris dataset_ has **too few** instances. Let's take _Fashion MNIST_ instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([0,1,2], dtype=tf.float32)\n",
    "tf.math.reduce_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "K = keras.backend\n",
    "#K.math.reduce_sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-16-9c036f0ad0a4> in <module>\n",
    "      1 import tensorflow.keras as keras\n",
    "      2 K = keras.backend\n",
    "----> 3 K.math.reduce_sum(a)\n",
    "\n",
    "AttributeError: module 'tensorflow.keras.backend' has no attribute 'math'\n",
    "```\n",
    "\n",
    "#### Instead, just do `K.sum(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wicked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    s = tf.math.reduce_sum(y_pred)\n",
    "    print(f\"s = {s}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    print(f\"tf.nn.softmax(y_pred) = {tf.nn.softmax(y_pred)}\")\n",
    "    print(f\"first_probas = {first_probas}\")\n",
    "    yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    print(f\"yy_pred = {yy_pred}\")\n",
    "    yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "                      true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "                      false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    )\n",
    "    print(f\"yy_true = {yy_true}\")\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=yy_true,\n",
    "        logits=yy_pred,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = -437.92999267578125\n",
      "tf.math.sigmoid(s) = 0.0\n",
      "last_proba = 1 - tf.math.sigmoid(s) = 1.0\n",
      "tf.nn.softmax(y_pred) = [0. 0. 1.]\n",
      "first_probas = [0. 0. 0.]\n",
      "yy_pred = [0. 0. 0. 1.]\n",
      "yy_true = [0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.74366844>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wicked_sigmoid(tf.constant([0,0,0], dtype=tf.float32), tf.constant([-500.0, -37.92, 99.99]))\n",
    "#crooked_sigmoid(tf.constant([0,0,0], dtype=tf.float32), tf.constant([-500.0, -37.92, 99.99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But...\n",
    "We are not so sure about the shape of `y_true` and `y_pred` in keras. How can we make sure of that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(9, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(train_labels, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 9), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(train_labels, depth=10)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 9])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(train_labels, depth=10)[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "#hey = encoder.fit_transform(train_labels[np.newaxis])\n",
    "hey = encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "hey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=wicked_sigmoid,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(train_labels, depth=10)[:,:-1].numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(train_images, tf.one_hot(train_labels, depth=10)[:,:-1], epochs=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ValueError: Shape must be rank 2 but is rank 1 for '{{node wicked_sigmoid/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](wicked_sigmoid/mul, wicked_sigmoid/concat/values_1, wicked_sigmoid/concat/axis)' with input shapes: [32,10], [1], []."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey.toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(train_images, hey.toarray()[:,:-1], epochs=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ValueError: Shape must be rank 2 but is rank 1 for '{{node wicked_sigmoid/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](wicked_sigmoid/mul, wicked_sigmoid/concat/values_1, wicked_sigmoid/concat/axis)' with input shapes: [32,10], [1], []."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't need `sklearn.preprocessing.OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 9)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(train_labels, depth=10)[:,:-1].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "s = Tensor(\"wicked_sigmoid/Sum:0\", shape=(), dtype=float32)\n",
      "tf.math.sigmoid(s) = Tensor(\"wicked_sigmoid/Sigmoid_1:0\", shape=(), dtype=float32)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = Tensor(\"wicked_sigmoid/sub:0\", shape=(), dtype=float32)\n",
      "tf.nn.softmax(y_pred) = Tensor(\"wicked_sigmoid/Softmax_1:0\", shape=(32, 10), dtype=float32)\n",
      "first_probas = Tensor(\"wicked_sigmoid/mul:0\", shape=(32, 10), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-7-ec2c57535c9c>:16 wicked_sigmoid  *\n        yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1654 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:1221 concat_v2\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal\n        ret = Operation(\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node wicked_sigmoid/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](wicked_sigmoid/mul, wicked_sigmoid/concat/values_1, wicked_sigmoid/concat/axis)' with input shapes: [32,10], [1], [].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-10bd1be81de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-7-ec2c57535c9c>:16 wicked_sigmoid  *\n        yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1654 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:1221 concat_v2\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal\n        ret = Operation(\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/phunc20/.virtualenvs/tf2.3.0-py3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node wicked_sigmoid/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](wicked_sigmoid/mul, wicked_sigmoid/concat/values_1, wicked_sigmoid/concat/axis)' with input shapes: [32,10], [1], [].\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, tf.one_hot(train_labels, depth=10)[:,:-1].numpy(), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum(input_tensor, axis=None, keepdims=False, name=None)\n",
      "    Computes the sum of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `axis` is None, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "    >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "    >>> x.numpy()\n",
      "    array([[1, 1, 1],\n",
      "           [1, 1, 1]], dtype=int32)\n",
      "    >>> # sum all the elements\n",
      "    >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "    >>> tf.reduce_sum(x).numpy()\n",
      "    6\n",
      "    >>> # reduce along the first dimension\n",
      "    >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "    >>> tf.reduce_sum(x, 0).numpy()\n",
      "    array([2, 2, 2], dtype=int32)\n",
      "    >>> # reduce along the second dimension\n",
      "    >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "    >>> tf.reduce_sum(x, 1).numpy()\n",
      "    array([3, 3], dtype=int32)\n",
      "    >>> # keep the original dimensions\n",
      "    >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "    array([[3],\n",
      "           [3]], dtype=int32)\n",
      "    >>> # reduce along both dimensions\n",
      "    >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "    >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "    >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "    >>> # 2 + 2 + 2 = 6\n",
      "    >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "    6\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "        dimensions. Must be in the range `[-rank(input_tensor),\n",
      "        rank(input_tensor)]`.\n",
      "      keepdims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor, of the same dtype as the input_tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "    int64 while tensorflow returns the same dtype as the input.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.math.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(train_labels, depth=10)[:,:-1].numpy()\n",
    "y_pred = np.empty_like(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 9), (60000, 9))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    print(f\"tf.nn.softmax(y_pred) = {tf.nn.softmax(y_pred)}\")\n",
    "    print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "InvalidArgumentError: Incompatible shapes: [60000] vs. [60000,9] [Op:Mul]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    first_probas = tf.math.multiply(tf.math.sigmoid(s), tf.nn.softmax(y_pred))\n",
    "    print(f\"tf.nn.softmax(y_pred) = {tf.nn.softmax(y_pred)}\")\n",
    "    print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "InvalidArgumentError: Incompatible shapes: [60000] vs. [60000,9] [Op:Mul]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 4, 9], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1,2,3]) * tf.constant([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function stack in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "stack(values, axis=0, name='stack')\n",
      "    Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.\n",
      "    \n",
      "    See also `tf.concat`, `tf.tile`, `tf.repeat`.\n",
      "    \n",
      "    Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "    each tensor in `values`, by packing them along the `axis` dimension.\n",
      "    Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
      "    \n",
      "    if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
      "    if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
      "    Etc.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    >>> x = tf.constant([1, 4])\n",
      "    >>> y = tf.constant([2, 5])\n",
      "    >>> z = tf.constant([3, 6])\n",
      "    >>> tf.stack([x, y, z])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]], dtype=int32)>\n",
      "    >>> tf.stack([x, y, z], axis=1)\n",
      "    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]], dtype=int32)>\n",
      "    \n",
      "    This is the opposite of unstack.  The numpy equivalent is `np.stack`\n",
      "    \n",
      "    >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))\n",
      "    True\n",
      "    \n",
      "    Args:\n",
      "      values: A list of `Tensor` objects with the same shape and type.\n",
      "      axis: An `int`. The axis to stack along. Defaults to the first dimension.\n",
      "        Negative values wrap around, so the valid range is `[-(R+1), R+1)`.\n",
      "      name: A name for this operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      output: A stacked `Tensor` with the same type as `values`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `axis` is out of the range [-(R+1), R+1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    #print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"yy_pred = {yy_pred}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09329853571724647"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (np.e + 8*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2536117142620283"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e / (np.e + 8*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 10), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([np.arange(10)]*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 9), dtype=int64, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "       [4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "       [5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "       [6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "       [7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
       "       [8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       [9, 9, 9, 9, 9, 9, 9, 9, 9]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([np.arange(10)]*9, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 5], dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(np.arange(3*5).reshape((3,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape([[1,2,3], [4,5,6]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape([[1,2,3], [4,5,6]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    first_probas = tf.stack([tf.math.sigmoid(s)]*tf.shape(y_pred)[1] , axis=1) * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"yy_pred = {yy_pred}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Mul]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.as_dtype(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(3, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    #print()\n",
    "    first_probas = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1) * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"yy_pred = {yy_pred}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n",
      "first_probas[1] = [1.6686453 0.6138603 0.6138603 0.6138603 0.6138603 0.6138603 0.6138603\n",
      " 0.6138603 0.6138603]\n",
      "first_probas.shape = (60000, 9)\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    #print()\n",
    "    #first_probas = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1) * tf.nn.softmax(y_pred)\n",
    "    #sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1)\n",
    "    print(f\"tf.shape(y_pred) = {tf.shape(y_pred)}\")\n",
    "    print(f\"tf.shape(y_pred)[1] = {tf.shape(y_pred)[1]}\")\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1]}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy()}\")\n",
    "    sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy(), axis=1)\n",
    "    print(f\"sigmoid_s_good_shape = {sigmoid_s_good_shape}\")\n",
    "    print(f\"sigmoid_s_good_shape.shape = {sigmoid_s_good_shape.shape}\")\n",
    "    print(f\"tf.cast(tf.shape(y_pred)[1], tf.float32) = {tf.cast(tf.shape(y_pred)[1], tf.float32)}\")\n",
    "    first_probas = sigmoid_s_good_shape * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"yy_pred = {yy_pred}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "tf.shape(y_pred) = [60000     9]\n",
      "tf.shape(y_pred)[1] = 9\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = [[0 0 0 ... 0 0 0]]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = [<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>]\n",
      "sigmoid_s_good_shape = [[0.5       0.5       0.5       ... 0.5       0.5       0.5      ]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " ...\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]]\n",
      "sigmoid_s_good_shape.shape = (60000, 9)\n",
      "tf.cast(tf.shape(y_pred)[1], tf.float32) = 9.0\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n",
      "first_probas[1] = [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      " 0.0682067  0.0682067  0.0682067 ]\n",
      "first_probas.shape = (60000, 9)\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[3]], dtype=int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([3])[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    #print()\n",
    "    #first_probas = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1) * tf.nn.softmax(y_pred)\n",
    "    #sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1)\n",
    "    print(f\"tf.shape(y_pred) = {tf.shape(y_pred)}\")\n",
    "    print(f\"tf.shape(y_pred)[1] = {tf.shape(y_pred)[1]}\")\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1]}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy()}\")\n",
    "    sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy(), axis=1)\n",
    "    print(f\"sigmoid_s_good_shape = {sigmoid_s_good_shape}\")\n",
    "    print(f\"sigmoid_s_good_shape.shape = {sigmoid_s_good_shape.shape}\")\n",
    "    print(f\"tf.cast(tf.shape(y_pred)[1], tf.float32) = {tf.cast(tf.shape(y_pred)[1], tf.float32)}\")\n",
    "    first_probas = sigmoid_s_good_shape * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"last_probas.shape = {last_probas.shape}\")\n",
    "    yy_pred = tf.concat([first_probas, last_proba[...,tf.newaxis]], axis=1)\n",
    "    print(f\"yy_pred[:3] = {yy_pred[:3]}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "tf.shape(y_pred) = [60000     9]\n",
      "tf.shape(y_pred)[1] = 9\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = [[0 0 0 ... 0 0 0]]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = [<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>]\n",
      "sigmoid_s_good_shape = [[0.5       0.5       0.5       ... 0.5       0.5       0.5      ]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " ...\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]]\n",
      "sigmoid_s_good_shape.shape = (60000, 9)\n",
      "tf.cast(tf.shape(y_pred)[1], tf.float32) = 9.0\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n",
      "first_probas[1] = [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      " 0.0682067  0.0682067  0.0682067 ]\n",
      "first_probas.shape = (60000, 9)\n",
      "yy_pred[:3] = [[0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      "  0.05555556 0.05555556 0.05555556 0.5       ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]]\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    #print()\n",
    "    #first_probas = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1) * tf.nn.softmax(y_pred)\n",
    "    #sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1)\n",
    "    print(f\"tf.shape(y_pred) = {tf.shape(y_pred)}\")\n",
    "    print(f\"tf.shape(y_pred)[1] = {tf.shape(y_pred)[1]}\")\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1]}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy()}\")\n",
    "    sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy(), axis=1)\n",
    "    print(f\"sigmoid_s_good_shape = {sigmoid_s_good_shape}\")\n",
    "    print(f\"sigmoid_s_good_shape.shape = {sigmoid_s_good_shape.shape}\")\n",
    "    print(f\"tf.cast(tf.shape(y_pred)[1], tf.float32) = {tf.cast(tf.shape(y_pred)[1], tf.float32)}\")\n",
    "    first_probas = sigmoid_s_good_shape * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"last_probas.shape = {last_probas.shape}\")\n",
    "    yy_pred = tf.concat([first_probas, last_proba[...,tf.newaxis]], axis=1)\n",
    "    print(f\"yy_pred[:3] = {yy_pred[:3]}\")\n",
    "    print(f\"tf.math.reduce_sum((yy_pred[:3], axis=1) = {tf.math.reduce_sum(yy_pred[:3], axis=1)}\")\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true) < 0.01,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    #print(f\"yy_true = {yy_true}\")\n",
    "    #return tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    labels=yy_true,\n",
    "    #    logits=yy_pred,\n",
    "    #)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-2.8311398e-09  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "tf.shape(y_pred) = [60000     9]\n",
      "tf.shape(y_pred)[1] = 9\n",
      "tf.math.sigmoid(s) = [0.5       0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = [[0 0 0 ... 0 0 0]]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = [<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.5      , 0.7310586, 0.7310586, ..., 0.7310586, 0.7310586,\n",
      "       0.7310586], dtype=float32)>]\n",
      "sigmoid_s_good_shape = [[0.5       0.5       0.5       ... 0.5       0.5       0.5      ]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " ...\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]\n",
      " [0.7310586 0.7310586 0.7310586 ... 0.7310586 0.7310586 0.7310586]]\n",
      "sigmoid_s_good_shape.shape = (60000, 9)\n",
      "tf.cast(tf.shape(y_pred)[1], tf.float32) = 9.0\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n",
      "first_probas[1] = [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      " 0.0682067  0.0682067  0.0682067 ]\n",
      "first_probas.shape = (60000, 9)\n",
      "yy_pred[:3] = [[0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      "  0.05555556 0.05555556 0.05555556 0.5       ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]]\n",
      "tf.math.reduce_sum((yy_pred[:3], axis=1) = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49995"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05555*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999536"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0682067*8 + 0.2689 + 0.1854"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.ones_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[1,0,0], [0,0,0], [0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False,  True, False])>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(y_true, axis=1) < tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False,  True, False])>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(y_true, axis=1) < 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.math.reduce_sum(y_true, axis=1) < tf.constant(0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "InvalidArgumentError: cannot compute Less as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Less]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.math.reduce_sum(y_true, axis=1) < 0.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "InvalidArgumentError: cannot compute Less as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Less]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.cond(tf.math.reduce_sum(y_true, axis=1) < 1, lambda: -3, lambda: 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function boolean_mask_v2 in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "boolean_mask_v2(tensor, mask, axis=None, name='boolean_mask')\n",
      "    Apply boolean mask to tensor.\n",
      "    \n",
      "    Numpy equivalent is `tensor[mask]`.\n",
      "    \n",
      "    ```python\n",
      "    # 1-D example\n",
      "    tensor = [0, 1, 2, 3]\n",
      "    mask = np.array([True, False, True, False])\n",
      "    boolean_mask(tensor, mask)  # [0, 2]\n",
      "    ```\n",
      "    \n",
      "    In general, `0 < dim(mask) = K <= dim(tensor)`, and `mask`'s shape must match\n",
      "    the first K dimensions of `tensor`'s shape.  We then have:\n",
      "      `boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]`\n",
      "    where `(i1,...,iK)` is the ith `True` entry of `mask` (row-major order).\n",
      "    The `axis` could be used with `mask` to indicate the axis to mask from.\n",
      "    In that case, `axis + dim(mask) <= dim(tensor)` and `mask`'s shape must match\n",
      "    the first `axis + dim(mask)` dimensions of `tensor`'s shape.\n",
      "    \n",
      "    See also: `tf.ragged.boolean_mask`, which can be applied to both dense and\n",
      "    ragged tensors, and can be used if you need to preserve the masked dimensions\n",
      "    of `tensor` (rather than flattening them, as `tf.boolean_mask` does).\n",
      "    \n",
      "    Args:\n",
      "      tensor:  N-D tensor.\n",
      "      mask:  K-D boolean tensor, K <= N and K must be known statically.\n",
      "      axis:  A 0-D int Tensor representing the axis in `tensor` to mask from. By\n",
      "        default, axis is 0 which will mask from the first dimension. Otherwise K +\n",
      "        axis <= N.\n",
      "      name:  A name for this operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      (N-K+1)-dimensional tensor populated by entries in `tensor` corresponding\n",
      "      to `True` values in `mask`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError:  If shapes do not conform.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    # 2-D example\n",
      "    tensor = [[1, 2], [3, 4], [5, 6]]\n",
      "    mask = np.array([True, False, True])\n",
      "    boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.boolean_mask)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "help(tf.bool)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.math.logical_or(tf.constant([0,0,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TypeError: logical_or() missing 1 required positional argument: 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function logical_or in module tensorflow.python.ops.gen_math_ops:\n",
      "\n",
      "logical_or(x, y, name=None)\n",
      "    Returns the truth value of x OR y element-wise.\n",
      "    \n",
      "    *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "    [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor` of type `bool`.\n",
      "      y: A `Tensor` of type `bool`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` of type `bool`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.math.logical_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0], [0, 0, 0], [0, 0, 1]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = tf.constant(y_true)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- tf.math.reduce_sum(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([y_true, (1- tf.math.reduce_sum(y_true, axis=1))[...,tf.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crooked_sigmoid(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Our customized loss function\n",
    "    Example: (4-class classification)\n",
    "        y_pred = [ -500.0, -37.92, 99.99]\n",
    "        y_true = [0, 0, 0]  # meaning that the true class is the fourth one.\n",
    "    \"\"\"\n",
    "    # I guess y_pred.shape equals (m, 9) for Fashion MNIST\n",
    "    s = tf.math.reduce_sum(y_pred, axis=1)\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"s.shape = {s.shape}\")\n",
    "    last_proba = 1 - tf.math.sigmoid(s)\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"tf.math.sigmoid(s).shape = {tf.math.sigmoid(s).shape}\")\n",
    "    print(f\"last_proba = 1 - tf.math.sigmoid(s) = {last_proba}\")\n",
    "    print(f\"last_proba.shape = {last_proba.shape}\")\n",
    "    #first_probas = tf.math.sigmoid(s) * tf.nn.softmax(y_pred)\n",
    "    #print()\n",
    "    #first_probas = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1) * tf.nn.softmax(y_pred)\n",
    "    #sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.cast(tf.shape(y_pred)[1], tf.float32) , axis=1)\n",
    "    print(f\"tf.shape(y_pred) = {tf.shape(y_pred)}\")\n",
    "    print(f\"tf.shape(y_pred)[1] = {tf.shape(y_pred)[1]}\")\n",
    "    print(f\"tf.math.sigmoid(s) = {tf.math.sigmoid(s)}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1]}\")\n",
    "    print(f\"[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = {[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy()}\")\n",
    "    sigmoid_s_good_shape = tf.stack([tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy(), axis=1)\n",
    "    print(f\"sigmoid_s_good_shape = {sigmoid_s_good_shape}\")\n",
    "    print(f\"sigmoid_s_good_shape.shape = {sigmoid_s_good_shape.shape}\")\n",
    "    print(f\"tf.cast(tf.shape(y_pred)[1], tf.float32) = {tf.cast(tf.shape(y_pred)[1], tf.float32)}\")\n",
    "    first_probas = sigmoid_s_good_shape * tf.nn.softmax(y_pred)\n",
    "    print(f\"y_pred[1] = {y_pred[1]}\")\n",
    "    print(f\"tf.nn.softmax(y_pred)[1] = {tf.nn.softmax(y_pred)[1]}\")\n",
    "    #print(f\"first_probas = {first_probas}\")\n",
    "    print(f\"first_probas[1] = {first_probas[1]}\")\n",
    "    print(f\"first_probas.shape = {first_probas.shape}\")\n",
    "    #yy_pred = tf.concat([first_probas, [last_proba]], axis=0)\n",
    "    #print(f\"last_probas.shape = {last_probas.shape}\")\n",
    "    yy_pred = tf.concat([first_probas, last_proba[...,tf.newaxis]], axis=1)\n",
    "    print(f\"yy_pred[:3] = {yy_pred[:3]}\")\n",
    "    print(f\"tf.math.reduce_sum((yy_pred[:3], axis=1) = {tf.math.reduce_sum(yy_pred[:3], axis=1)}\")\n",
    "    ## Wrong!\n",
    "    #yy_true = tf.cond(tf.math.reduce_sum(y_true, axis=1) < 1,\n",
    "    #                  true_fn=lambda: tf.concat([y_true, [1]], 0),\n",
    "    #                  false_fn=lambda: tf.concat([y_true, [0]], 0),\n",
    "    #)\n",
    "    yy_true = tf.concat([y_true, (1- tf.math.reduce_sum(y_true, axis=1))[...,tf.newaxis]], axis=1)\n",
    "    print(f\"yy_true[:4] =\\n{yy_true[:4]}\")\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=yy_true,\n",
    "        logits=yy_pred,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.one_hot(train_labels, depth=10)[:,:-1].numpy()\n",
    "y_pred = np.empty_like(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = [-1.4926147e-07  1.0000000e+00  1.0000000e+00 ...  1.0000000e+00\n",
      "  1.0000000e+00  1.0000000e+00]\n",
      "s.shape = (60000,)\n",
      "tf.math.sigmoid(s) = [0.49999997 0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      "tf.math.sigmoid(s).shape = (60000,)\n",
      "last_proba = 1 - tf.math.sigmoid(s) = [0.5       0.2689414 0.2689414 ... 0.2689414 0.2689414 0.2689414]\n",
      "last_proba.shape = (60000,)\n",
      "tf.shape(y_pred) = [60000     9]\n",
      "tf.shape(y_pred)[1] = 9\n",
      "tf.math.sigmoid(s) = [0.49999997 0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1] = [[0 0 0 ... 0 0 0]]\n",
      "[tf.math.sigmoid(s)]*tf.shape(y_pred)[1].numpy() = [<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>, <tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
      "array([0.49999997, 0.7310586 , 0.7310586 , ..., 0.7310586 , 0.7310586 ,\n",
      "       0.7310586 ], dtype=float32)>]\n",
      "sigmoid_s_good_shape = [[0.49999997 0.49999997 0.49999997 ... 0.49999997 0.49999997 0.49999997]\n",
      " [0.7310586  0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      " [0.7310586  0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      " ...\n",
      " [0.7310586  0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      " [0.7310586  0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]\n",
      " [0.7310586  0.7310586  0.7310586  ... 0.7310586  0.7310586  0.7310586 ]]\n",
      "sigmoid_s_good_shape.shape = (60000, 9)\n",
      "tf.cast(tf.shape(y_pred)[1], tf.float32) = 9.0\n",
      "y_pred[1] = [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.nn.softmax(y_pred)[1] = [0.2536117  0.09329854 0.09329854 0.09329854 0.09329854 0.09329854\n",
      " 0.09329854 0.09329854 0.09329854]\n",
      "first_probas[1] = [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      " 0.0682067  0.0682067  0.0682067 ]\n",
      "first_probas.shape = (60000, 9)\n",
      "yy_pred[:3] = [[0.05555555 0.05555555 0.05555554 0.05555555 0.05555555 0.05555555\n",
      "  0.05555555 0.05555555 0.05555555 0.5       ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]\n",
      " [0.18540503 0.0682067  0.0682067  0.0682067  0.0682067  0.0682067\n",
      "  0.0682067  0.0682067  0.0682067  0.2689414 ]]\n",
      "tf.math.reduce_sum((yy_pred[:3], axis=1) = [1. 1. 1.]\n",
      "yy_true[:4] =\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
       "array([1.9125932, 2.2194638, 2.2194638, ..., 2.2194638, 2.2194638,\n",
       "       2.2194638], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crooked_sigmoid(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
